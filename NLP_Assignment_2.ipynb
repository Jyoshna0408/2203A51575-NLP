{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqJAWqlFIn7gMvFKy6ZzST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyoshna0408/2203A51575-NLP/blob/main/NLP_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *NATURAL LANGUAGE PROCESSING*\n",
        "# **ASSIGNMENT - 2**"
      ],
      "metadata": {
        "id": "U11OYu8sAg0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Implementation of Tokenization in the text**"
      ],
      "metadata": {
        "id": "l1DA8vLjAjPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ma6WpNG_5aR",
        "outputId": "35850c33-173c-4f63-afe8-7230d7f8bab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Hello', 'everyone', '!'],\n",
              "  ['The', 'NLP', 'class', 'is', 'interesting', '.'],\n",
              "  ['Is', \"n't\", 'it', '?']]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "text = \"\"\"Hello everyone! The NLP class is interesting.\n",
        "        Isn't it?\"\"\"\n",
        "\n",
        "def para_tokenize(text):\n",
        "    para = text.split('\\n\\n')\n",
        "    return para\n",
        "\n",
        "para = para_tokenize(text)\n",
        "tokenized_text = []\n",
        "for p in para:\n",
        "    sentences = sent_tokenize(p)\n",
        "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "    tokenized_text.append(tokenized_sentences)\n",
        "tokenized_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Implementation of Stemming in the text.**"
      ],
      "metadata": {
        "id": "-0f3lovjApna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "words = [\"running\", \"ran\", \"runs\", \"easily\", \"fairly\"]\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "porter_stems = [porter_stemmer.stem(word) for word in words]\n",
        "print(\"Porter Stemmer Results:\")\n",
        "print(porter_stems)\n",
        "lancaster_stems = [lancaster_stemmer.stem(word) for word in words]\n",
        "print(\"\\nLancaster Stemmer Results:\")\n",
        "print(lancaster_stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aViTV4crAAeJ",
        "outputId": "6305705d-b2b6-4451-ae5b-7717c23d5e3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer Results:\n",
            "['run', 'ran', 'run', 'easili', 'fairli']\n",
            "\n",
            "Lancaster Stemmer Results:\n",
            "['run', 'ran', 'run', 'easy', 'fair']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Implement representation of word on any text.**"
      ],
      "metadata": {
        "id": "5oSnk1G7A4dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "text = [\"This is Natural Language Processing.\",\n",
        "        \"Linguistics and Computer Science are a part of NLP.\"]\n",
        "\n",
        "count_vect=CountVectorizer()\n",
        "count_vector = count_vect.fit_transform(text)\n",
        "print(\"Reperesentation of Count vector:\\n\", count_vector.toarray())\n",
        "print(\"Feature Names:\", count_vect.get_feature_names_out())\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vector = tfidf_vect.fit_transform(text)\n",
        "print(\"TF-IDF Vector Representation:\\n\", tfidf_vector.toarray())\n",
        "print(\"Feature Names:\", tfidf_vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDEQd6-uAZN3",
        "outputId": "4f1f2db8-eadb-4f56-fcc6-b78d08a74cbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reperesentation of Count vector:\n",
            " [[0 0 0 1 1 0 1 0 0 0 1 0 1]\n",
            " [1 1 1 0 0 1 0 1 1 1 0 1 0]]\n",
            "Feature Names: ['and' 'are' 'computer' 'is' 'language' 'linguistics' 'natural' 'nlp' 'of'\n",
            " 'part' 'processing' 'science' 'this']\n",
            "TF-IDF Vector Representation:\n",
            " [[0.         0.         0.         0.4472136  0.4472136  0.\n",
            "  0.4472136  0.         0.         0.         0.4472136  0.\n",
            "  0.4472136 ]\n",
            " [0.35355339 0.35355339 0.35355339 0.         0.         0.35355339\n",
            "  0.         0.35355339 0.35355339 0.35355339 0.         0.35355339\n",
            "  0.        ]]\n",
            "Feature Names: ['and' 'are' 'computer' 'is' 'language' 'linguistics' 'natural' 'nlp' 'of'\n",
            " 'part' 'processing' 'science' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Implementation Representation of Sentences**"
      ],
      "metadata": {
        "id": "wyvHNMCiCdbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "sentences = [\"Welcome to the Jupyter notebook. Let's perform representation of the sentences.\"]\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(sentences)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "print(\"Words Representation: \")\n",
        "print(bow_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_2R6a3ECXCP",
        "outputId": "d8a1eaf9-7acd-4173-dae3-72cb40d53fa3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words Representation: \n",
            "   jupyter  let  notebook  of  perform  representation  sentences  the  to  \\\n",
            "0        1    1         1   1        1               1          1    2   1   \n",
            "\n",
            "   welcome  \n",
            "0        1  \n"
          ]
        }
      ]
    }
  ]
}